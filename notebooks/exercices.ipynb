{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CACBFsndOCo"
      },
      "source": [
        "# Exercices"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Préliminaires**: Clone de votre repo et imports"
      ],
      "metadata": {
        "id": "hfkMtaHleKAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/nouhalahyen/exam_2025.git\n",
        "! cp exam_2025/utils/utils_exercices.py .\n",
        "\n",
        "import copy\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from utils_exercices import Dataset1"
      ],
      "metadata": {
        "id": "xiD_cI-geJjI",
        "outputId": "bcc1a977-9fe0-47dc-8194-267b2edd406d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'exam_2025' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clef personnelle pour la partie théorique**\n",
        "\n",
        "Dans la cellule suivante, choisir un entier entre 100 et 1000 (il doit être personnel). Cet entier servira de graine au générateur de nombres aléatoire a conserver pour tous les exercices.\n",
        "\n"
      ],
      "metadata": {
        "id": "J3ga_6BNc5DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mySeed = 300"
      ],
      "metadata": {
        "id": "PrCTHM4od5UZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "TRWBLVpCWC06"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5RcggmAkJLV"
      },
      "source": [
        "\\\n",
        "\n",
        "**Exercice 1** *Une relation linéaire*\n",
        "\n",
        "La fonction *generate_dataset* fournit deux jeux de données (entraînement et test). Pour chaque jeu de données, la clef 'inputs' donne accès à un tableau numpy (numpy array) de prédicteurs empilés horizontalement : chaque ligne $i$ contient trois prédicteurs $x_i$, $y_i$ et $z_i$. La clef 'targets' renvoie le vecteur des cibles $t_i$. \\\n",
        "\n",
        "Les cibles sont liées aux prédicteurs par le modèle:\n",
        "$$ t = \\theta_0 + \\theta_1 x + \\theta_2 y + \\theta_3 z + \\epsilon$$ où $\\epsilon \\sim \\mathcal{N}(0,\\eta)$\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils_exercices import generate_dataset, Dataset1\n",
        "train_set, test_set = generate_dataset(mySeed)"
      ],
      "metadata": {
        "id": "gEQmgTI8my8i"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** Par quelle méthode simple peut-on estimer les coefficients $\\theta_k$ ? La mettre en oeuvre avec la librairie python de votre choix."
      ],
      "metadata": {
        "id": "q5XZTrXNk12K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour déterminer les coefficients $\\theta$, on applique la méthode des moindres carrés, qui consiste à minimiser la somme des carrés des écarts :\n",
        "\n",
        "$$\n",
        "\\min ||X\\theta - y||^2\n",
        "$$\n",
        "\n",
        "où $X$ représente la matrice des variables prédictives et $y$ est le vecteur des observations. La solution analytique s'écrit comme suit :\n",
        "\n",
        "$$\n",
        "\\theta = (X^T X)^{-1} X^T y\n",
        "$$"
      ],
      "metadata": {
        "id": "6R5QAgbQkHV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import inv\n",
        "\n",
        "# Données d'entraînement\n",
        "X = train_set['inputs']\n",
        "y = train_set['targets']\n",
        "\n",
        "# Ajout d'une colonne de biais (1)\n",
        "X_b = np.hstack([X, np.ones((X.shape[0], 1))])\n",
        "\n",
        "# Calcul de \\theta\n",
        "theta_hat = inv(X_b.T @ X_b) @ X_b.T @ y\n",
        "print(\"Coefficients estimés (theta):\", theta_hat)\n"
      ],
      "metadata": {
        "id": "HITtUqHhFMkn",
        "outputId": "c08b860e-bccb-47bc-f8d2-3f97850517d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients estimés (theta): [ 2.97230274  2.9365536   5.85815285 15.01770145]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MXGXg8tlPULY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Dans les cellules suivantes, on se propose d'estimer les $\\theta_k$ grâce à un réseau de neurones entraîné par SGD. Quelle architecture s'y prête ? Justifier en termes d'expressivité et de performances en généralisation puis la coder dans la cellule suivante."
      ],
      "metadata": {
        "id": "CH_Z5ZEIlQPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour estimer les coefficients $\\theta_k$, une architecture simple, comme un réseau de neurones avec une seule couche linéaire entièrement connectée, est bien adaptée. Cette configuration est suffisante pour capturer une relation linéaire, tout en réduisant le risque de sur-apprentissage et en maintenant une capacité d'apprentissage efficace sur les données.\n"
      ],
      "metadata": {
        "id": "f4STs7D6keSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset et dataloader :\n",
        "dataset = Dataset1(train_set['inputs'], train_set['targets'])\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)\n",
        "\n",
        "# A coder :\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc = nn.Linear(3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "PPx543blnxdb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Entraîner cette architecture à la tâche de régression définie par les entrées et sorties du jeu d'entraînement (compléter la cellule ci-dessous)."
      ],
      "metadata": {
        "id": "g6BSTBitpGBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, loss, and optimizer\n",
        "mySimpleNet = SimpleNet()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(mySimpleNet.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_inputs, batch_targets in dataloader:\n",
        "        # Forward pass : calcul des prédictions\n",
        "        predictions = mySimpleNet(batch_inputs)\n",
        "\n",
        "        # Calcul de la perte\n",
        "        loss = criterion(predictions, batch_targets)\n",
        "\n",
        "        # Backward pass : calcul du gradient\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Mise à jour des poids\n",
        "        optimizer.step()\n",
        "\n",
        "    # Afficher la perte toutes les 50 époques\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "Wjfa2Z4RoPO-",
        "outputId": "a248139e-72eb-4b99-8ac7-b9f3bb519d12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/500, Loss: 24.8701\n",
            "Epoch 100/500, Loss: 30.8892\n",
            "Epoch 150/500, Loss: 26.8858\n",
            "Epoch 200/500, Loss: 27.9139\n",
            "Epoch 250/500, Loss: 43.0794\n",
            "Epoch 300/500, Loss: 32.3304\n",
            "Epoch 350/500, Loss: 30.7474\n",
            "Epoch 400/500, Loss: 28.7571\n",
            "Epoch 450/500, Loss: 33.6057\n",
            "Epoch 500/500, Loss: 34.9630\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Où sont alors stockées les estimations des  $\\theta_k$ ? Les extraire du réseau *mySimpleNet* dans la cellule suivante."
      ],
      "metadata": {
        "id": "OZwKogEEp2Fr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les coefficients $\\theta_k$ estimés sont enregistrés dans les paramètres de la couche linéaire du réseau, à savoir :  \n",
        "- Les poids  de la couche linéaire.  \n",
        "- Le biais  de la couche linéaire.\n"
      ],
      "metadata": {
        "id": "MKtTJv5Bl8Y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = mySimpleNet.fc.weight.data.numpy()\n",
        "bias = mySimpleNet.fc.bias.data.numpy()\n",
        "\n",
        "print(\"Coefficients estimés (poids) :\", weights)\n",
        "print(\"Biais estimé :\", bias)"
      ],
      "metadata": {
        "id": "EjgWp1y1rseb",
        "outputId": "495cc006-9e21-4803-a180-4746b8535aab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients estimés (poids) : [[0.01707954 0.01955457 0.05218352]]\n",
            "Biais estimé : [17.971333]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5** Tester ces estimations sur le jeu de test et comparer avec celles de la question 1. Commentez."
      ],
      "metadata": {
        "id": "pEB-V-oOrJED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Q5 Tester les estimations sur le jeu de test et les comparer avec celles de la question 1. Fournir une analyse.\n",
        "\n",
        "# Prédictions sur le jeu de test avec les coefficients estimés du modèle linéaire (Q1)\n",
        "X_test = test_set['inputs']\n",
        "y_test = test_set['targets']\n",
        "X_test_with_bias = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
        "y_pred_linear = X_test_with_bias @ theta_hat\n",
        "\n",
        "# Prédictions sur le jeu de test avec le réseau de neurones entraîné (Q4)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_pred_nn = mySimpleNet(X_test_tensor).detach().numpy().flatten()\n",
        "\n",
        "# Calcul des erreurs quadratiques moyennes (MSE) pour chaque méthode\n",
        "mse_linear = np.mean((y_test - y_pred_linear)**2)\n",
        "mse_nn = np.mean((y_test - y_pred_nn)**2)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(f\"MSE (Modèle linéaire - Question 1) : {mse_linear}\")\n",
        "print(f\"MSE (Réseau de neurones - Question 4) : {mse_nn}\")\n",
        "\n",
        "# Comparaison des performances\n",
        "print(\"Analyse des performances :\")\n",
        "if mse_linear < mse_nn:\n",
        "    print(\"Le modèle linéaire (Q1) offre de meilleures performances sur le jeu de test.\")\n",
        "elif mse_linear > mse_nn:\n",
        "    print(\"Le réseau de neurones (Q4) offre de meilleures performances sur le jeu de test.\")\n",
        "else:\n",
        "    print(\"Les deux méthodes présentent des performances équivalentes sur le jeu de test.\")\n"
      ],
      "metadata": {
        "id": "VpfV2MOSmWzx",
        "outputId": "6ec43de3-bd5a-4aea-9ec5-4407809b4548",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE (Modèle linéaire - Question 1) : 4.09572233590508\n",
            "MSE (Réseau de neurones - Question 4) : 32.9152994601767\n",
            "Analyse des performances :\n",
            "Le modèle linéaire (Q1) offre de meilleures performances sur le jeu de test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "VvV2jIrBNtzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice 2** *Champ réceptif et prédiction causale*"
      ],
      "metadata": {
        "id": "CpRvXCaAtsIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le réseau défini dans la cellule suivante est utilisé pour faire le lien entre les valeurs $(x_{t' \\leq t})$ d'une série temporelle d'entrée et la valeur présente $y_t$ d'une série temporelle cible."
      ],
      "metadata": {
        "id": "8JG9wTfK5TBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from utils_exercices import Outconv, Up_causal, Down_causal\n",
        "\n",
        "class Double_conv_causal(nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2, with causal convolutions that preserve input size'''\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=3, dilation=1):\n",
        "        super(Double_conv_causal, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dilation = dilation\n",
        "        self.conv1 = nn.Conv1d(in_ch, out_ch, kernel_size=kernel_size, padding=0, dilation=dilation)\n",
        "        self.bn1 = nn.BatchNorm1d(out_ch)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv1d(out_ch, out_ch, kernel_size=kernel_size, padding=0, dilation=dilation)\n",
        "        self.bn2 = nn.BatchNorm1d(out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.pad(x, ((self.kernel_size - 1) * self.dilation, 0))\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = F.pad(x, ((self.kernel_size - 1) * self.dilation, 0))\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class causalFCN(nn.Module):\n",
        "    def __init__(self, dilation=1):\n",
        "        super(causalFCN, self).__init__()\n",
        "        size = 64\n",
        "        n_channels = 1\n",
        "        n_classes = 1\n",
        "        self.inc = Double_conv_causal(n_channels, size)\n",
        "        self.down1 = Down_causal(size, 2*size)\n",
        "        self.down2 = Down_causal(2*size, 4*size)\n",
        "        self.down3 = Down_causal(4*size, 8*size, pooling_kernel_size=5, pooling_stride=5)\n",
        "        self.down4 = Down_causal(8*size, 4*size, pooling=False, dilation=2)\n",
        "        self.up2 = Up_causal(4*size, 2*size, kernel_size=5, stride=5)\n",
        "        self.up3 = Up_causal(2*size, size)\n",
        "        self.up4 = Up_causal(size, size)\n",
        "        self.outc = Outconv(size, n_classes)\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up2(x5, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.outc(x)\n",
        "        return x\n",
        "\n",
        "# Exemple d'utilisation\n",
        "model = causalFCN()\n",
        "# Série temporelle d'entrée (x_t):\n",
        "input_tensor1 = torch.rand(1, 1, 10000)\n",
        "# Série temporelle en sortie f(x_t):\n",
        "output = model(input_tensor1)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "id": "fIbU1EJT1MM9",
        "outputId": "fdfca09f-0fa5-4609-c58c-f61f59b4b25f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** De quel type de réseau de neurones s'agit-il ? Combien de paramètres la couche self.Down1 compte-t-elle (à faire à la main) ?\n",
        "Combien de paramètres le réseau entier compte-t-il (avec un peu de code) ?"
      ],
      "metadata": {
        "id": "-mNnsYU-7R7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le réseau est un Fully Convolutional Network (FCN) avec des convolutions causales. Ces convolutions assurent que chaque sortie $y_t$ ne dépend que des entrées $x_{t'}$ pour lesquelles $t' \\leq t$, respectant ainsi la causalité dans les séries temporelles. Cela en fait un modèle particulièrement adapté aux contextes séquentiels pour la prédiction des valeurs cibles.\n",
        "\n",
        "Calcul du nombre de paramètres pour la couche self.down1 :\n",
        "\n",
        "    Formule pour une couche Conv1d :\n",
        "    Nombre de parameˋtres=(in_ch×out_ch×kernel_size)+out_chNombre de parameˋtres=(in_ch×out_ch×kernel_size)+out_ch\n",
        "\n",
        "    Formule pour une couche BatchNorm1d :\n",
        "    Nombre de parameˋtres=2×out_chNombre de parameˋtres=2×out_ch\n",
        "\n",
        "Pour self.down1 :\n",
        "\n",
        "    Canaux d'entrée : $in_ch = 64$, canaux de sortie : $out_ch = 128$, taille du noyau : $kernel_size = 3$\n",
        "    Conv1d:(64×128×3)+128=24672Conv1d:(64×128×3)+128=24672\n",
        "    BatchNorm1d:2×128=256BatchNorm1d:2×128=256\n",
        "    Nombre total :\n",
        "    24672+256=24928 parameˋtres24672+256=24928 parameˋtres\n",
        "\n",
        "Calcul du nombre total de paramètres du réseau :\n",
        "\n",
        "En additionnant les paramètres de toutes les couches, le réseau contient :\n",
        "Nombre total de parameˋtres=2872641\n"
      ],
      "metadata": {
        "id": "U-7lrj0FnBca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(model.down1)\n",
        "# parameters self.down1\n",
        "for name, param in model.down1.named_parameters():\n",
        "    print(f\"Layer: {name}, Parameters: {param.numel()}\")\n",
        "\n",
        "# number total of parameters:\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Nombre total de paramètres : {total_params}\")"
      ],
      "metadata": {
        "id": "qlYxUf6U9vH1",
        "outputId": "c6bdc2df-c300-4f09-f6d6-d3ec9441a1ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Down_causal(\n",
            "  (mpconv): Sequential(\n",
            "    (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (1): Double_conv_causal(\n",
            "      (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
            "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
            "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Layer: mpconv.1.conv1.weight, Parameters: 24576\n",
            "Layer: mpconv.1.conv1.bias, Parameters: 128\n",
            "Layer: mpconv.1.bn1.weight, Parameters: 128\n",
            "Layer: mpconv.1.bn1.bias, Parameters: 128\n",
            "Layer: mpconv.1.conv2.weight, Parameters: 49152\n",
            "Layer: mpconv.1.conv2.bias, Parameters: 128\n",
            "Layer: mpconv.1.bn2.weight, Parameters: 128\n",
            "Layer: mpconv.1.bn2.bias, Parameters: 128\n",
            "Nombre total de paramètres : 2872641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Par quels mécanismes la taille du vecteur d'entrée est-elle réduite ? Comment est-elle restituée dans la deuxième partie du réseau ?"
      ],
      "metadata": {
        "id": "I4D46A0-8LaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Réduction de la dimension du vecteur d'entrée\n",
        "\n",
        "Dans la première partie du réseau, la taille du vecteur d'entrée est réduite grâce aux opérations suivantes :\n",
        "\n",
        "#### **1. Pooling dans les couches `Down_causal`**  \n",
        "- Les couches de pooling, comme `MaxPool1d`, diminuent la longueur de la séquence en sous-échantillonnant les données.  \n",
        "- Par exemple, un `MaxPool1d` avec un `kernel_size=2` et un `stride=2` réduit la longueur de la séquence de moitié.\n",
        "\n",
        "---\n",
        "\n",
        "### Restauration de la dimension dans la seconde partie du réseau\n",
        "\n",
        "La taille du vecteur est progressivement restaurée dans la deuxième partie du réseau via les mécanismes suivants :  \n",
        "\n",
        "#### **1. Upsampling dans les couches `Up_causal`**  \n",
        "- Ces couches utilisent des convolutions transposées ou des techniques similaires pour augmenter la longueur du vecteur.  \n",
        "- Par exemple, une couche `Up_causal` avec un `kernel_size=5` et un `stride=5` multiplie la longueur de la séquence par 5.  \n",
        "\n",
        "#### **2. Concatenation avec les sorties intermédiaires**  \n",
        "- Lors de l'upsampling, les sorties intermédiaires des couches descendantes (`down1`, `down2`, etc.) sont concaténées avec les sorties des couches montantes correspondantes (`up2`, `up3`, etc.).  \n",
        "- Cette opération permet de récupérer les informations perdues pendant la réduction de la taille et améliore la précision globale du modèle.  \n"
      ],
      "metadata": {
        "id": "E8mt6kBLn9lR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Par quels mécanismes le champ réceptif est-il augmenté ? Préciser par un calcul la taille du champ réceptif en sortie de *self.inc*."
      ],
      "metadata": {
        "id": "SVNeFnm88yV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Méthodes pour augmenter le champ réceptif\n",
        "\n",
        "Le champ réceptif est élargi grâce aux mécanismes suivants :\n",
        "\n",
        "### 1. Convolutions avec des kernels de grande taille  \n",
        "Chaque couche de convolution capture les informations sur plusieurs pas de temps, ce qui élargit le champ réceptif.\n",
        "\n",
        "### 2. Convolutions dilatées (dilated convolutions)  \n",
        "En insérant des \"espaces\" entre les éléments pris en compte par le kernel, la dilatation permet de couvrir une plage plus large sans augmenter le nombre de paramètres.\n",
        "\n",
        "### 3. Empilement de couches convolutionnelles  \n",
        "Les couches successives augmentent progressivement le champ réceptif. Chaque couche dépend des sorties de la précédente, qui intègrent déjà des informations sur une plage étendue.\n",
        "\n",
        "---\n",
        "\n",
        "## Calcul du champ réceptif de `self.inc`\n",
        "\n",
        "La couche `self.inc` est composée de deux convolutions successives : `conv1` et `conv2`, avec les caractéristiques suivantes :  \n",
        "- **Taille du kernel** : `kernel_size = 3`  \n",
        "- **Dilatation** : `dilation = 1`  \n",
        "\n",
        "### Formule générale pour le calcul du champ réceptif  \n",
        "\\[\n",
        "\\text{Champ réceptif} = (\\text{kernel\\_size} - 1) \\times (\\text{dilation} + 1) + 1\n",
        "\\]\n",
        "\n",
        "### Étapes de calcul :\n",
        "\n",
        "#### 1. Champ réceptif de `conv1`  \n",
        "\\[\n",
        "\\text{Champ\\_réceptif\\_conv1} = (3 - 1) \\times (1 + 1) + 1 = 3\n",
        "\\]\n",
        "\n",
        "#### 2. Champ réceptif de `conv2`  \n",
        "Le champ réceptif de `conv2` prend en compte celui de `conv1` :  \n",
        "\\[\n",
        "\\text{Champ\\_réceptif\\_conv2} = (\\text{Champ\\_réceptif\\_conv1} - 1) + ((3 - 1) \\times (1 + 1) + 1)\n",
        "\\]  \n",
        "\\[\n",
        "\\text{Champ\\_réceptif\\_conv2} = (3 - 1) + 3 = 5\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "## Résultat final  \n",
        "Le champ réceptif total de la couche `self.inc` est :  \n",
        "\\[\n",
        "\\textbf{5}\n",
        "\\]\n",
        "\n"
      ],
      "metadata": {
        "id": "dfF-yOx3obQk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "w-vjh4jHoGKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Par un bout de code, déterminer empiriquement la taille du champ réceptif associé à la composante $y_{5000}$ du vecteur de sortie. (Indice: considérer les sorties associées à deux inputs qui ne diffèrent que par une composante...)"
      ],
      "metadata": {
        "id": "TVVcBPuA9EP0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "69WMWCSZAg5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5** $y_{5000}$ dépend-elle des composantes $x_{t, \\space t > 5000}$ ? Justifier de manière empirique puis préciser la partie du code de Double_conv_causal qui garantit cette propriété de \"causalité\" en justifiant.  \n",
        "\n"
      ],
      "metadata": {
        "id": "gZ37skwm-Vpv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PeooRYE-ATGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "qV52tusgNn6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "Exercice 3: \"Ranknet loss\""
      ],
      "metadata": {
        "id": "bm-sRzmfqc2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un [article récent](https://https://arxiv.org/abs/2403.14144) revient sur les progrès en matière de learning to rank. En voilà un extrait :"
      ],
      "metadata": {
        "id": "Wl8wUjsSM57D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src=\"https://raw.githubusercontent.com/nanopiero/exam_2025/refs/heads/main/utils/png_exercice3.PNG?token=GHSAT0AAAAAAC427DACOPGNDNN6UDOLVLLAZ4BB2JQ\" alt=\"extrait d'un article\" width=\"800\">"
      ],
      "metadata": {
        "id": "SDZUXMlSDpoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** Qu'est-ce que les auteurs appellent \"positive samples\" et \"negative samples\" ? Donner un exemple."
      ],
      "metadata": {
        "id": "9NzV1PbMNyuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Dans l'expression de $\\mathcal{L}_{RankNet}$, d'où proviennent les $z_i$ ? Que représentent-ils ?  "
      ],
      "metadata": {
        "id": "yIKQ5Eo9OnPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Pourquoi cette expression conduit-elle à ce que, après apprentissage, \"the estimated\n",
        "value of positive samples is greater than that of negative samples\n",
        "for each pair of positive/negative samples\" ?"
      ],
      "metadata": {
        "id": "r74fWiyvPb7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Dans le cadre d'une approche par deep learning, quels termes utilise-t-on pour qualifier les réseaux de neurones exploités et la modalité suivant laquelle ils sont entraînés ?"
      ],
      "metadata": {
        "id": "pk1EIi_VVi3R"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}