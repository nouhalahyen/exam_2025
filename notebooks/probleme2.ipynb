{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problème n°2: PointNet"
      ],
      "metadata": {
        "id": "-1ciEeyNevrd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certains jeux de données impliquent des nuages de points dans un espace 3D. Penser par exemple à un ensemble de mesures lidar : chaque tir permet de renseigner les coordonnées d'un des points de l'objet ciblé.\n",
        "Une tâche intéressante consiste à classer chacun des points du nuage en fonction de l'objet auquel il appartient. Cette tâche est considérée comme une variante de la segmentation sémantique d'images.\n",
        "\n",
        "Ce problème introduit à une méthode directe de segmentation d'un nuage par deep learning. Elle est basée sur une architecture particulière appelée PointNet. \\\n",
        "Dans la première partie, on présente un jeu de données (synthétisé à la volée) impliquant des nuages de points.\n",
        "Dans la seconde partie, on explore la structure et les propriétés de PointNet. Dans la troisième, on l'entraîne et dans la dernière partie, on charge les poids d'une version améliorée de PointNet (PointNet++) pour comparaison.\n",
        "\n",
        "La cellule suivante permet les imports nécessaires:"
      ],
      "metadata": {
        "id": "rPIFraX86pZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "! pip install einops\n",
        "! git clone https://github.com/nouhalahyen/exam_2025.git\n",
        "! cp exam_2025/utils/utils_probleme2.py .\n",
        "from utils_probleme2 import gen_pointcloud, plot_triplets"
      ],
      "metadata": {
        "id": "VMhc4--pzPdB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "c1b07580-7db5-4dcf-88c0-72caedd2fcb1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "function 'conv1d' already has a docstring",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-57e769bc8001>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m \u001b[0;31m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2016\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_VF\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfunctional\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# usort: skip # noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_add_docstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mUninitializedParameter\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mUninitializedParameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# usort: skip # noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from torch.nn import (\n\u001b[1;32m     10\u001b[0m     \u001b[0mattention\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModule\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBilinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIdentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyLinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinear\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m from .activation import (\n\u001b[1;32m      4\u001b[0m     \u001b[0mCELU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mELU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUninitializedParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m conv1d = _add_docstr(\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     r\"\"\"\n",
            "\u001b[0;31mRuntimeError\u001b[0m: function 'conv1d' already has a docstring"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie I : un exemple de PointCLoud data"
      ],
      "metadata": {
        "id": "OXcPslsLOKEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour construire le jeu de données, on simule un terrain couvert de deux types de bâtiments : des immeubles de forme rectangulaire aux toits plats et des igloos (dômes). Pour créer les nuages, on échantillonne les surfaces vues du ciel (les murs des bâtiments rectangulaires ne sont pas échantillonnées), en favorisant les zones d'altitude non nulles.\n",
        "Le but est de distinguer les igloos du reste (sol et toits des bâtiments). Il s'agit donc d'une segmentation binaire."
      ],
      "metadata": {
        "id": "GDqmLGFROPJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 6\n",
        "input_points, target_list, target_points  = gen_pointcloud(batch_size)\n",
        "\n",
        "\n",
        "for i in range(batch_size):\n",
        "  print(i)\n",
        "  # Représentation 3D des nuages de points et\n",
        "  # les paramètres elev et azim permettent de changer l'angle de vue\n",
        "  plot_triplets(input_points[i].transpose(0,1).cpu(),\n",
        "                elev=75, azim=0)\n",
        "\n",
        "  # Cibles : les points appartenant aux toitures d'igloos sont\n",
        "  # dans la classe 1, les autres, dans la classe 0.\n",
        "  plot_triplets(target_points[i].transpose(0,1).cpu(),\n",
        "                title='Cibles',\n",
        "                cbar_label='classe')\n",
        "\n",
        "  # Note: target_points contient non seulement les classes\n",
        "  # mais aussi les coordonnées x et y des points, pour\n",
        "  # faciliter leur visualisation"
      ],
      "metadata": {
        "id": "uBvv7mzq8SXZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "6d99e4bf-7ed8-4bb4-ee42-507399aa6034"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'gen_pointcloud' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5195749b3b92>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_points\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mgen_pointcloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gen_pointcloud' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** A quoi correspondent les différentes dimensions de *input_points* ?"
      ],
      "metadata": {
        "id": "Ec1hdpYKWqtY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "N x 3 : Où N est le nombre de points dans le nuage, et chaque point est défini par ses coordonnées (x, y, z) en 3D.\n",
        "Chaque ligne représente un point unique du nuage, et les colonnes contiennent les informations suivantes :\n",
        "\n",
        "    x : Coordonnée spatiale horizontale (axe 1).\n",
        "    y : Coordonnée spatiale verticale (axe 2).\n",
        "    z : Hauteur ou altitude du point."
      ],
      "metadata": {
        "id": "ST71r5L_3yBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Les points d'un nuage sont-ils rangés dans un ordre particulier ?"
      ],
      "metadata": {
        "id": "O29XO_-BXW3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les coordonnées en entrée de input_points servent à :\n",
        "\n",
        "    Décrire la structure géométrique du nuage de points en 3D.\n",
        "    Permettre la segmentation binaire :\n",
        "        Les coordonnées (x, y, z) aident à différencier les formes (plat pour les immeubles et courbé pour les igloos).\n",
        "    Capturer les caractéristiques spécifiques à chaque type de bâtiment (ex. : hauteur constante pour les toits plats vs variation pour les dômes)."
      ],
      "metadata": {
        "id": "1AgZc5Zx30c5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** (question ouverte). Si vous deviez traiter le problème avec un FCN ou un ViT (Visual Transformer), que feriez-vous ?"
      ],
      "metadata": {
        "id": "9VdTYIGMZkYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Traitement avec un FCN\n",
        "\n",
        "Un FCN est conçu pour des données structurées comme des images 2D ou des volumes 3D réguliers. Voici comment je procéderais :\n",
        "Étapes :\n",
        "\n",
        "    Représentation des nuages de points :\n",
        "        Convertir les nuages de points 3D en une grille régulière (voxelisation). Chaque voxel serait une cellule 3D contenant un point ou un ensemble de points.\n",
        "        Les valeurs dans la grille pourraient être des indicateurs binaire (présence/absence d’un point) ou des statistiques locales (ex. : densité, coordonnées moyennes).\n",
        "\n",
        "    Entrée du modèle :\n",
        "        Alimenter cette grille voxelisée dans un FCN 3D qui applique des convolutions volumétriques pour extraire les caractéristiques locales et globales.\n",
        "\n",
        "    Prédictions :\n",
        "        Produire une segmentation volumétrique où chaque voxel est classifié comme appartenant ou non à un igloo.\n",
        "\n",
        "Avantages :\n",
        "\n",
        "    Exploite directement les capacités des FCNs pour traiter des données structurées.\n",
        "    Approche bien comprise et optimisée pour les grilles régulières.\n",
        "\n",
        "Inconvénients :\n",
        "\n",
        "    Perte d’information due à la voxelisation, en particulier si la grille est de faible résolution pour limiter la mémoire.\n",
        "    Consommation mémoire élevée, car une grille volumétrique dense peut être très coûteuse.\n",
        "\n",
        "2. Traitement avec un ViT\n",
        "\n",
        "Les ViTs peuvent capturer les relations globales entre les points, mais leur utilisation sur des nuages de points nécessite une adaptation importante.\n",
        "Étapes :\n",
        "\n",
        "    Extraction de patchs :\n",
        "        Traiter les points 3D comme une séquence d'entités. Chaque point ou petit groupe de points serait transformé en un vecteur d'entrée via une petite MLP (Multi-Layer Perceptron) ou un encodage géométrique (ex. : coordonnées (x, y, z) avec des features comme la densité locale).\n",
        "\n",
        "    Encodage positionnel :\n",
        "        Ajouter des informations de position (comme dans les ViTs pour les images) pour indiquer la localisation spatiale des points.\n",
        "\n",
        "    Application du Transformer :\n",
        "        Passer la séquence de vecteurs à travers un Transformer classique (avec des mécanismes d'attention) pour capturer les relations globales entre les points.\n",
        "\n",
        "    Prédictions finales :\n",
        "        Utiliser une tête de segmentation pour classer chaque point en fonction de ses caractéristiques globales et locales apprises par le Transformer.\n",
        "\n",
        "Avantages :\n",
        "\n",
        "    Capture les relations globales entre les points grâce au mécanisme d'attention.\n",
        "    Flexible pour des tâches de segmentation et classification.\n",
        "\n",
        "Inconvénients :\n",
        "\n",
        "    Gourmand en données : Les ViTs nécessitent généralement un grand volume de données annotées pour apprendre efficacement.\n",
        "    Coût computationnel élevé, surtout pour des séquences longues (grands nuages de points).\n",
        "\n"
      ],
      "metadata": {
        "id": "kjuRtWtr4sAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie II : le modèle PointNet"
      ],
      "metadata": {
        "id": "Oi-tMb6eVseg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cette partie, on s'intéresse à la propriété principale d'un réseau PointNet : l'utilisation d'opérations invariantes par rapport à l'ordre dans lequel les points sont présentés au réseau."
      ],
      "metadata": {
        "id": "ymRoRLYE1_AN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils_probleme2 import PointNetSegHead\n",
        "pointnet = PointNetSegHead(num_points=800, num_global_feats=1024, m=2).cuda()\n",
        "\n",
        "input_points, target_list, _ = gen_pointcloud(batch_size)\n",
        "input_points = input_points.cuda()\n",
        "output, _, _ = pointnet(input_points)"
      ],
      "metadata": {
        "id": "S04tXJXHQWJ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "e4f47fe9-182c-4182-a8e0-bfbc99159573"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'utils_probleme2'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2b2ad8afa2ef>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils_probleme2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPointNetSegHead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpointnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPointNetSegHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_global_feats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_pointcloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_points\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils_probleme2'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** La sortie du modèle PointNet correspond au premier tenseur du *tuple* fourni la fonction *forward* de *pointnet*. A quoi correspondent les différentes dimensions de *output* ? Quel est l'effet d'une permutation des points contenus dans *inputs_points* sur la sortie ? Répondre :\n",
        "\n",
        "- en vous référant à l'article [l'article](https://arxiv.org/abs/1612.00593) qui introduit ce réseau (citer dans le texte).\n",
        "- à partir de tests à effectuer dans la cellule de code suivante (utiliser torch.randperm pour générer des permutations sur les entrées)"
      ],
      "metadata": {
        "id": "JzuMy_0l2Kbr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dimensions de output :\n",
        "\n",
        "    Si l'entrée est de dimension (batch_size, N, D) où :\n",
        "        batch_size : Nombre de nuages de points dans un batch.\n",
        "        N : Nombre de points dans chaque nuage.\n",
        "        D : Dimensions des caractéristiques pour chaque point (e.g., coordonnées (x, y, z)).\n",
        "    La sortie output de PointNet a typiquement deux parties :\n",
        "        Un vecteur global (extrait par agrégation, par exemple via max pooling) de dimension (batch_size, G) où G est la dimension des caractéristiques globales.\n",
        "        Des caractéristiques locales pour chaque point de dimension (batch_size, N, F) où F est la dimension des caractéristiques pour chaque point.\n",
        "\n",
        "Effet d'une permutation :\n",
        "\n",
        "    PointNet est conçu pour être invariant aux permutations des points grâce aux mécanismes suivants :\n",
        "        Les opérations appliquées point par point (comme des MLP partagées) ne dépendent pas de l'ordre.\n",
        "        L'agrégation globale (souvent via max pooling) combine les informations de manière indépendante de l'ordre.\n",
        "    Ainsi, une permutation des points dans input_points ne modifie pas la sortie globale (vecteur agrégé)."
      ],
      "metadata": {
        "id": "Rd_x5wR45ojk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Justification : Dans l'article PointNet (Qi et al., 2017), cette propriété est obtenue par l'utilisation de :\n",
        "\n",
        "    Opérations partagées (les mêmes transformations pour chaque point).\n",
        "    Agrégation symétrique (ex. : max pooling), garantissant que l’ordre n’impacte pas le résultat."
      ],
      "metadata": {
        "id": "0ofWwIy_59mD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "99d6FryC7Bty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** L'architecture de *pointnet* est décrite dans la Figure 2 de l'article (voir ci-dessous) évoqué à la question précédente. En dehors des opérations notées \"input transform\" et \"feature transform\", dont la compréhension est plus délicate, quelles sont les différentes opérations conduisant à une segmentation ? Que signifie le terme \"shared\" et expliquer en quoi ces opérations sont invariantes par rapport à l'ordre de présentation des points."
      ],
      "metadata": {
        "id": "9a3Ag6gf7XWX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= https://miro.medium.com/v2/resize:fit:1100/format:webp/1*lFnrIqmV_47iRvQcY3dB7Q.png >"
      ],
      "metadata": {
        "id": "Rhf7Jzr9yJwb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Opérations conduisant à la segmentation :\n",
        "\n",
        "    MLP partagées : Des couches fully connected appliquées à chaque point indépendamment. Chaque point est traité de la même manière pour extraire des caractéristiques locales.\n",
        "    Max pooling : Une opération d’agrégation symétrique qui extrait des caractéristiques globales du nuage en combinant les informations locales.\n",
        "    Concaténation : Les caractéristiques locales (par point) et globales (vecteur agrégé) sont combinées pour produire une segmentation fine.\n",
        "    MLP finales : Les couches fully connected finales effectuent la classification (binaire ou multi-classes) de chaque point.\n",
        "\n",
        "Signification de \"shared\" :\n",
        "\n",
        "    Les poids des MLP sont partagés pour tous les points d’un nuage.\n",
        "    Cela garantit que chaque point est traité de manière identique, indépendamment de son positionnement ou de l'ordre des autres points."
      ],
      "metadata": {
        "id": "-TJrHQVl6HOA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Opérations conduisant à la segmentation :\n",
        "\n",
        "    MLP partagées : Des couches fully connected appliquées à chaque point indépendamment. Chaque point est traité de la même manière pour extraire des caractéristiques locales.\n",
        "    \n",
        "    Max pooling : Une opération d’agrégation symétrique qui extrait des caractéristiques globales du nuage en combinant les informations locales.\n",
        "    Concaténation : Les caractéristiques locales (par point) et globales (vecteur agrégé) sont combinées pour produire une segmentation fine.\n",
        "    MLP finales : Les couches fully connected finales effectuent la classification (binaire ou multi-classes) de chaque point.\n",
        "\n",
        "Signification de \"shared\" :\n",
        "\n",
        "    Les poids des MLP sont partagés pour tous les points d’un nuage.\n",
        "    Cela garantit que chaque point est traité de manière identique, indépendamment de son positionnement ou de l'ordre des autres points.\n",
        "\n",
        "Les MLP appliquent la même transformation à chaque point, ce qui ne dépend pas de l’ordre.\n",
        "L'agrégation symétrique (e.g., max pooling) garantit que l’ordre n’influence pas le vecteur global."
      ],
      "metadata": {
        "id": "73a7TEwX6M0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie III"
      ],
      "metadata": {
        "id": "6ivNzt2E86eJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cette partie, on se propose d'entraîner un PointNet. Pour ce faire, on utilisera une fonction de coût spécifique (voir cellule ci-dessous).\n",
        "\n",
        "**Consignes :**\n",
        "\n",
        "1) Entraîner un PointNet sur quelques centaines d'époques.\n",
        "\n",
        "2) Afficher à chaque époque la justesse des prédictions\n",
        "\n",
        "3) Charger les poids d'un réseau entraîné sur 500 époques, stockés dans le fichier **pointnet_500_ep.pth** du répertoire https://huggingface.co/nanopiero/pointnet_igloos.\n",
        "\n",
        "Visualiser les sorties de ce modèle-là en complétant le la dernière cellule de code du calepin.\n"
      ],
      "metadata": {
        "id": "Hah5_qJ78-6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(pointnet.parameters(),\n",
        "                             lr=0.0001, betas=(0.9, 0.999))\n",
        "\n",
        "# manually set alpha weights\n",
        "alpha = np.array([0.2, 0.8])\n",
        "gamma = 1\n",
        "loss_fn = PointNetSegLoss(alpha=alpha, gamma=gamma, dice=True).cuda()\n",
        "\n",
        "# exemple d'utilisation de PointNetSegLoss:\n",
        "# La transposition permet de repasser la dimension relative\n",
        "# aux probabilités en dernier, comme avec torch.nn.CrossEntropyLoss\n",
        "proba_pred_list = outputs.transpose(1,2)\n",
        "loss_fn(proba_pred_list, target_list)"
      ],
      "metadata": {
        "id": "VwA_vclx0CWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "n_epochs = 200\n",
        "n_batch_per_epoch = 10\n",
        "\n",
        "\n",
        "for epoch in range(1, n_epochs):\n",
        "  print('epoch : ', epoch)\n",
        "  for batch in range(1,n_batch_per_epoch):\n",
        "    ..."
      ],
      "metadata": {
        "id": "CNW_PJ_aAkBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_points, target_list , target_points = gen_pointcloud(6)\n",
        "\n",
        "# Il faut construire les prédictions.\n",
        "proba_pred_list, _, _ = pointnet2.cuda()(input_points.to(device))\n",
        "pred_list = proba_pred_list.transpose(1,2).max(1)[1].cpu()\n",
        "\n",
        "# Accuracy:\n",
        "...\n",
        "# Tracé\n",
        "\n",
        "for i in range(6):\n",
        "  print(i)\n",
        "  plot_triplets(input_points[i].transpose(0,1), elev=75, azim=0)\n",
        "  plot_triplets(target_points[i].transpose(0,1),\n",
        "                title='Cibles',\n",
        "                cbar_label='classe')\n",
        "  plot_triplets(...,\n",
        "                title='Predictions',\n",
        "                cbar_label='classe')\n"
      ],
      "metadata": {
        "id": "OjFZ3ZNS-riv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}